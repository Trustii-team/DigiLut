{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b1690d9",
   "metadata": {},
   "source": [
    "# 1) We start by importing the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce823752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import prismtoolbox as ptb\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import openslide\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patches as mplpatches\n",
    "from skimage.util import view_as_windows\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.utils import wpx_ratio, bpx_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe7b58",
   "metadata": {},
   "source": [
    "# 2) We define the location of raw images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e645eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder = \"../data/raw/images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a7526",
   "metadata": {},
   "source": [
    "# 3) We import csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57f4692",
   "metadata": {},
   "outputs": [],
   "source": [
    "lesions_df = pd.read_csv(\"../data/raw/presence_of_lesion.csv\")\n",
    "lesions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6483a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/raw/train.csv\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b3f6c6",
   "metadata": {},
   "source": [
    "# 4) We identify slides with no lesions and no bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a4ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_slides = [f\"{file.split('_')[0]}.tif\" for file in train_df.filename]\n",
    "negative_slides = lesions_df[lesions_df.presence_of_lesion==0&~lesions_df.file_name.isin(train_slides)].file_name.values\n",
    "negative_slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a3dd2",
   "metadata": {},
   "source": [
    "### Due to some problems in our code, not all these slides were considered and some slides with a lesions were considered a negatives. To reproduce exactly the results of the submission, please consider the following slides as negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263699e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/slides_considered_as_negative.csv\")\n",
    "negative_slides = np.unique([f\"{file.split('_')[0]}.tif\" for file in df.filename])\n",
    "negative_slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a267f3",
   "metadata": {},
   "source": [
    "# 5) We extract patches from training data with no lesions that will be labelled as negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da5ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_contours_train =  \"../data/processed/train_negatives/contours\"\n",
    "directory_visualize_train = \"../data/processed/train_negatives/contoured_images\"\n",
    "directory_patches_train = \"../data/processed/train_negatives/patches\"\n",
    "directory_patches_as_jpg_train = \"../data/processed/train_negatives/patches_as_jpg_1000\"\n",
    "directory_stitch_train = \"../data/processed/train_negatives/stitch_images\"\n",
    "\n",
    "Path(directory_contours_train).mkdir(parents=True, exist_ok=True)\n",
    "Path(directory_visualize_train).mkdir(parents=True, exist_ok=True)\n",
    "Path(directory_patches_train).mkdir(parents=True, exist_ok=True)\n",
    "Path(directory_patches_as_jpg_train).mkdir(parents=True, exist_ok=True)\n",
    "Path(directory_stitch_train).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d320544",
   "metadata": {},
   "source": [
    "### To speed up processing, we selected randomly 1000 patches to save from each slide. The slides were contoured and patches were curated with high threshold to discard as much artifacts as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe8892",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(os.listdir(raw_data_folder)):\n",
    "    filename = file.split(\".tif\")[0]\n",
    "    if os.path.exists(os.path.join(directory_stitch_train, f\"{filename}.jpg\")) or not f\"{filename.split('_')[0]}.tif\" in negative_slides:\n",
    "        continue\n",
    "    WSI_object = ptb.WSI(slide_path=os.path.join(raw_data_folder, file), engine=\"openslide\")\n",
    "    # Extract tissue contours\n",
    "    params_detect_tissue = {\"seg_level\": 6, \"window_avg\": 30, \"window_eng\": 3, \"thresh\": 110, \"area_min\": 1.5e3}\n",
    "\n",
    "    WSI_object.detect_tissue(**params_detect_tissue)\n",
    "\n",
    "    WSI_object.save_tissue_contours(directory_contours_train)\n",
    "\n",
    "    img = WSI_object.visualize(vis_level=6, number_contours=True)\n",
    "\n",
    "    img.save(os.path.join(directory_visualize_train, f\"{filename}.jpg\"))\n",
    "\n",
    "    params_patches = {\"patch_size\": 512, \"patch_level\": 0, \"step_size\": 512, \"mode\": \"contours\", \"contours_mode\": \"four_pt_hard\",\n",
    "                      \"rgb_threshs\":(2, 180), \"percentages\": (0.6, 0.7)}\n",
    "\n",
    "    WSI_object.extract_patches(**params_patches)\n",
    "    #WSI_object.save_patches(directory_patches_train)\n",
    "    \n",
    "    selected_idx = rng.choice(len(WSI_object.coords), 1000)\n",
    "    WSI_object.save_patches(os.path.join(directory_patches_as_jpg_train, file), selected_idx=selected_idx, file_format=\"jpg\")\n",
    "\n",
    "    img = WSI_object.stitch(vis_level=6)\n",
    "\n",
    "    img.save(os.path.join(directory_stitch_train, f\"{filename}.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c2bf7",
   "metadata": {},
   "source": [
    "# 6) We extract patches from all validation slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_contours_val =  \"../data/processed/val/contours\"\n",
    "directory_visualize_val = \"../dataprocessed/val/contoured_images\"\n",
    "directory_patches_val = \"../data/processed/val/patches\"\n",
    "directory_patches_as_jpg_val = \"../data/processed/val/patches_as_jpg_full\"\n",
    "directory_stitch_val = \"../data/processed/val/stitch_images\"\n",
    "\n",
    "Path(directory_contours_val).mkdir(parents=True, exist_ok=True)\n",
    "Path(directory_visualize_val).mkdir(parents=True, exist_ok=True)\n",
    "Path(directory_patches_val).mkdir(parents=True, exist_ok=True)\n",
    "Path(directory_patches_as_jpg_val).mkdir(parents=True, exist_ok=True)\n",
    "Path(directory_stitch_val).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e6e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(\"../data/raw/validation.csv\")\n",
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0a125c",
   "metadata": {},
   "source": [
    "### The threshold were changed to ensure we retrieved as much as possible all the tissue with minimum artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e6e791",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(os.listdir(raw_data_folder)):\n",
    "    if file not in val_df.filename.values or os.path.exists(os.path.join(directory_stitch_val, f\"{filename}.jpg\")):\n",
    "        continue\n",
    "    WSI_object = ptb.WSI(slide_path=os.path.join(raw_data_folder, file), engine=\"openslide\")\n",
    "    # Extract tissue contours\n",
    "    params_detect_tissue = {\"seg_level\": 5, \"window_avg\": 30, \"window_eng\": 5, \"thresh\": 180, \"area_min\": 6e3}\n",
    "\n",
    "    WSI_object.detect_tissue(**params_detect_tissue)\n",
    "\n",
    "    WSI_object.save_tissue_contours(directory_contours_val)\n",
    "\n",
    "    img = WSI_object.visualize(vis_level=6, number_contours=True)\n",
    "\n",
    "    img.save(os.path.join(directory_visualize_val, file.replace(\".tif\", \".jpg\")))\n",
    "\n",
    "    params_patches = {\"patch_size\": 512, \"patch_level\": 0, \"step_size\": 512, \"mode\": \"contours\", \"contours_mode\": \"four_pt_hard\",\n",
    "                      \"rgb_threshs\":(2, 240), \"percentages\": (0.6, 0.7)}\n",
    "\n",
    "    WSI_object.extract_patches(**params_patches)\n",
    "\n",
    "    WSI_object.save_patches(directory_patches_val)\n",
    "\n",
    "    WSI_object.save_patches(os.path.join(directory_patches_as_jpg_val, file), file_format=\"jpg\")\n",
    "\n",
    "    img = WSI_object.stitch(vis_level=6)\n",
    "\n",
    "    img.save(os.path.join(directory_stitch, file.replace(\".tif\", \".jpg\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b342c3",
   "metadata": {},
   "source": [
    "# 7) We extract positive patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "white_perc, black_perc = 0.9, 0.1 #threshholds for the % of white and black pixels in a patch read from the slide\n",
    "vis_scale = 0.008\n",
    "patch_size =(512, 512)\n",
    "\n",
    "seed=2024\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d008a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/raw/train.csv')\n",
    "df_valid = pd.read_csv('../data/raw/validation.csv')\n",
    "df_lesions = pd.read_csv('../data/raw/presence_of_lesion.csv')\n",
    "print(df_train.shape, df_valid.shape, df_lesions.shape)\n",
    "\n",
    "df_train['patient'] = df_train['filename'].apply(lambda x: x.split('_')[0])\n",
    "df_train['width']=df_train['x2']-df_train['x1']\n",
    "df_train['height']=df_train['y2']-df_train['y1']\n",
    "df_valid['patient'] = df_valid['filename'].apply(lambda x: x.split('_')[0])\n",
    "df_lesions['patient'] = df_lesions['file_name'].apply(lambda x: x.split('.')[0])\n",
    "all_patients = len(df_train[\"patient\"].unique())\n",
    "df_wrong = pd.DataFrame(columns=[\"patient\", \"filename\", \"x1\", \"x2\", \"y1\", \"y2\"], index=range(len(os.listdir('../data/raw/Boundig Box IDs'))))\n",
    "\n",
    "for i,e in enumerate([e for e in os.listdir('../data/raw/Boundig Box IDs') if '.jpeg' in e]):\n",
    "    try:\n",
    "        p, l, x1,x2, y1, y2 = e.split('_')\n",
    "        df_wrong.iloc[i] = [p, p+'_'+l+'.tif', x1,x2, y1, y2.split('.')[0]]\n",
    "    except Exception as exp: \n",
    "        print(e, e.split('_'), exp)\n",
    "df_wrong = df_wrong.dropna()\n",
    "display(df_wrong)\n",
    "df_wrong.to_csv('../data/raw/wrong_bbox.csv', index=False)\n",
    "print('raw data:')\n",
    "print(\"train patients\", len(df_train['patient'].unique()), \"train slides\",len(df_train['filename'].unique()),)\n",
    "print(\"valid patients\", len(df_valid['patient'].unique()), \"valid slides\", len(df_valid['filename'].unique()))\n",
    "\n",
    "indices = []\n",
    "for p in df_wrong.filename.unique():\n",
    "    for x1,x2, y1, y2 in df_wrong.loc[df_wrong[\"filename\"]==p][[\"x1\", \"x2\", \"y1\", \"y2\"]].values:\n",
    "        selected_row = df_train.loc[(df_train[\"filename\"]==p) & (df_train[\"x1\"]==int(x1))]\n",
    "        if len(selected_row) > 0:\n",
    "            indices.append(selected_row.index.item())\n",
    "df_train = df_train.drop(indices)\n",
    "\n",
    "print(\"\\neliminate wrong Bboxes:\")\n",
    "print(\"train patients\", len(df_train['patient'].unique()), \"train slides\",len(df_train['filename'].unique()),)\n",
    "print(\"valid patients\", len(df_valid['patient'].unique()), \"valid slides\", len(df_valid['filename'].unique()))\n",
    "intersection_tr_vl = set(df_train['patient'].unique())&set(df_valid['patient'].unique())\n",
    "\n",
    "print(\"\\nintersection between train and validation:\", len(intersection_tr_vl))\n",
    "print(\"train no label in presence_of_lesion:\",set(df_train['patient'].unique())-set(df_lesions['patient'].unique()))\n",
    "print(\"valid no label in presence_of_lesion:\",set(df_valid['patient'].unique())-set(df_lesions['patient'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['patient','filename', 'x1', 'x2', 'y1', 'y2', 'max_x', 'max_y', \"width\", \"height\", 'presence_of_lesion']\n",
    "df_train = pd.merge(df_train, df_lesions, on=[\"patient\"])\n",
    "df_train = df_train[train_cols]\n",
    "df_test = df_train.loc[df_train['patient'].isin(intersection_tr_vl)]\n",
    "df_train = df_train.loc[~df_train['patient'].isin(intersection_tr_vl)]\n",
    "\n",
    "print('\\nafter merging with presence_of_lesion:')\n",
    "print(\"train patients\", len(df_train['patient'].unique()), len(df_train['patient'].unique())/all_patients, \"train slides\",len(df_train['filename'].unique()),)\n",
    "print(\"test patients\", len(df_test['patient'].unique()), len(df_test['patient'].unique())/all_patients,  \"test slides\",len(df_test['filename'].unique()),)\n",
    "\n",
    "all_slides = os.listdir(\"../data/raw/images\")\n",
    "train_slides = df_train['filename'].unique().tolist()\n",
    "test_slides = df_test['filename'].unique().tolist()\n",
    "valid_slides = df_valid['filename'].unique().tolist()\n",
    "annotated_slides = train_slides + test_slides + valid_slides\n",
    "\n",
    "print('\\ndata slides:', len(all_slides))\n",
    "print('train slides:', len(train_slides))\n",
    "print('test slides:', len(test_slides))\n",
    "print('valid slides:', len(valid_slides))\n",
    "print('annotated slides:', len(annotated_slides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a2b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df_train, df_test], axis=0)\n",
    "data = data.loc[data['presence_of_lesion']==1]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d829ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"../data/processed/positive_patches_bis\").mkdir(parents=True, exist_ok=True)\n",
    "non_valid_slides = []\n",
    "removed_patches = []\n",
    "bw_vals = []\n",
    "s=0\n",
    "for idx in tqdm(range(len(data['filename'].unique()))):\n",
    "    slide_name = data['filename'].unique()[idx]\n",
    "    directory_positive_patches = \"../data/processed/positive_patches_bis\"+'/'+slide_name.split('.')[0]\n",
    "    Path(directory_positive_patches).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    slide = openslide.OpenSlide('../data/raw/images/'+slide_name)\n",
    "    cols = len(data.loc[data['filename']==slide_name])\n",
    "\n",
    "    images = []\n",
    "    for i in range(cols):\n",
    "        x1 = data.loc[data['filename']==slide_name].iloc[i]['x1']\n",
    "        x2 = data.loc[data['filename']==slide_name].iloc[i]['x2']\n",
    "        y1 = data.loc[data['filename']==slide_name].iloc[i]['y1']\n",
    "        y2 = data.loc[data['filename']==slide_name].iloc[i]['y2']\n",
    "        image = slide.read_region((x1,y1), level=0, size=(x2-x1, y2-y1)).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        try:\n",
    "            if image.shape[0]>=patch_size[0] and image.shape[1]>=patch_size[1]:\n",
    "                image_height, image_width, _ = image.shape\n",
    "                new_height = ((image_height + patch_size[0] - 1) // patch_size[0]) * patch_size[0]\n",
    "                new_width = ((image_width + patch_size[1] - 1) // patch_size[1]) * patch_size[1]\n",
    "                image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)\n",
    "                patches = view_as_windows(image, (patch_size[0], patch_size[1], 3), step=patch_size[1])\n",
    "                patches = view_as_windows(image, (patch_size[0], patch_size[1], 3), step=patch_size[1])\n",
    "                for i in range(patches.shape[0]):\n",
    "                    for j in range(patches.shape[1]):\n",
    "                        w_val = wpx_ratio(patches[i, j, 0])\n",
    "                        b_val = bpx_ratio(patches[i, j, 0])\n",
    "                        if w_val<white_perc  and b_val<black_perc:\n",
    "                            plt.imsave(f'{directory_positive_patches}/{slide_name.split(\".\")[0]}_x1_{x1}_x2_{x2}_y1_{y1}_y2_{y2}_i_{patch_size[0]*i}_j_{patch_size[1]*j}.jpg', arr=patches[i, j, 0])\n",
    "                            s+=1\n",
    "                        else:\n",
    "                            w_val = wpx_ratio(patches[i, j, 0])\n",
    "                            removed_patches.append(patches[i, j, 0])\n",
    "                            bw_vals.append(w_val)\n",
    "            else:\n",
    "                image = cv2.resize(image, (patch_size[0], patch_size[1]), interpolation=cv2.INTER_LANCZOS4)\n",
    "                plt.imsave(f'{directory_positive_patches}/{slide_name.split(\".\")[0]}_x1_{x1}_x2_{x2}_y1_{y1}_y2_{y2}_resized.jpg', arr=image)\n",
    "                s+=1\n",
    "        except Exception as e:\n",
    "            non_valid_slides.append(slide_name)\n",
    "            print(slide_name, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4173d92",
   "metadata": {},
   "source": [
    "# 8) Create training dataframes for classification model without cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359145dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"patient\", \"filename\", \"x1\", \"y1\", \"x2\", \"y2\", \"i\", \"j\", \"image\", \"label\", \"path\"]\n",
    "pos_df = pd.DataFrame(columns=cols, index=range(0, 10**4))\n",
    "k=0\n",
    "for slide in tqdm(os.listdir('../data/processed/positive_patches')):\n",
    "    for patch in os.listdir(f'../data/processed/positive_patches/{slide}'):\n",
    "        if '.ipynb' not in patch:\n",
    "            l = patch.split('_')\n",
    "            image, label = patch, 1\n",
    "            p, s, x1, y1, x2, y2 = l[0], l[0]+\"_\"+l[1], l[3], l[5], l[7], l[9]\n",
    "            path = f'../data/processed/positive_patches/{slide}/'\n",
    "            if \"resized\" in patch:\n",
    "                i, j =  -1, -1\n",
    "            else:\n",
    "                i, j = l[11], l[13].split('.')[0]\n",
    "            pos_df.loc[k] = [p, s+'.tif', x1, y1, x2, y2, i, j, image, label, path]\n",
    "            k+=1\n",
    "pos_df = pos_df.dropna()\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43583ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 1000\n",
    "cols = [\"patient\", \"filename\", \"x1\", \"y1\", \"x2\", \"y2\", \"image\", \"label\", \"path\"]\n",
    "neg_df = pd.DataFrame(columns=cols, index=range(0, len(os.listdir(\"../data/processed/train_negatives/patches_as_jpg_1000/\"))*thresh))\n",
    "\n",
    "k=0\n",
    "for slide in tqdm(os.listdir(\"../data/processed/train_negatives/patches_as_jpg_1000/\")):\n",
    "    if len(os.listdir(\"../data/processed/train_negatives/patches_as_jpg_1000/\"+slide))<thresh:\n",
    "        liste = os.listdir(\"../data/processed/train_negatives/patches_as_jpg_1000/\"+slide)\n",
    "    else:\n",
    "        liste = random.sample(os.listdir(\"../data/processed/train_negatives/patches_as_jpg_1000/\"+slide), k=thresh)\n",
    "    path = \"../data/processed/train_negatives/patches_as_jpg_1000/\"+slide+'/'\n",
    "    for patch in liste:\n",
    "        if '.ipynb' not in patch:\n",
    "            l = patch.split('_')\n",
    "            image, label = patch, 0\n",
    "            p, s, x1, y1, x2, y2 = l[0], l[0]+\"_\"+l[1], l[2], l[3].split('.')[0], int(l[2])+512, int(l[3].split('.')[0])+512\n",
    "            neg_df.loc[k] = [p, s+'.tif', x1, y1, x2, y2, image, label, path]\n",
    "            k+=1\n",
    "neg_df = neg_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv('../data/raw/validation.csv')\n",
    "df_valid['patient'] = df_valid['filename'].apply(lambda x: x.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f5d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_valid['patient'].unique())==131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([pos_df, neg_df], ignore_index=True)\n",
    "train_patches = final_df.loc[final_df['filename'].isin(df_train['filename'])]\n",
    "test_patches = final_df.loc[final_df['filename'].isin(df_test['filename'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d1ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(train_patches['patient'].values) & set(test_patches['patient'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbad052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(train_patches['filename'].values) & set(test_patches['filename'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches.to_csv('../data/processed/dataframe_training_selected.csv', index=False)\n",
    "test_patches.to_csv('../data/processed/dataframe_testing_selected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d88b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for slide in tqdm(df_valid['filename'].unique()):\n",
    "    try:\n",
    "        liste = os.listdir(\"../data/processed/val/patches_as_jpg_full/\"+slide)\n",
    "        path = \"../data/processed/val/patches_as_jpg_full/\"+slide+'/'\n",
    "        for patch in liste:\n",
    "            if '.ipynb' not in patch:\n",
    "                k+=1\n",
    "    except Exception as e:\n",
    "        print(e, slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad60273",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"patient\", \"filename\", \"image\", \"path\"]\n",
    "val_df = pd.DataFrame(columns=cols, index=range(k+1))\n",
    "\n",
    "k=0\n",
    "for slide in tqdm(df_valid['filename'].unique()):\n",
    "    try:\n",
    "        liste = os.listdir(\"../data/processed/val/patches_as_jpg_full/\"+slide)\n",
    "        path = \"../data/processed/val/patches_as_jpg_full/\"+slide+'/'\n",
    "        for patch in liste:\n",
    "            if '.ipynb' not in patch:\n",
    "                l = patch.split('_')\n",
    "                image = patch\n",
    "                p, s = l[0], l[0]+\"_\"+l[1]\n",
    "                val_df.loc[k] = [p, s+'.tif', image, path]\n",
    "                k+=1\n",
    "    except Exception as e:\n",
    "        print(e, slide)\n",
    "val_df = val_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.to_csv('../data/processed/dataframe_validation_selected.csv', index=False)\n",
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a7b260",
   "metadata": {},
   "source": [
    "# 9) 5-Folds Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3282569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed=2024\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4541e145",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "def create_stratified_folds(df, target_column, n_splits, seed=seed):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    df['fold'] = -1\n",
    "    for fold, (_, val_idx) in enumerate(skf.split(df, df[target_column])):\n",
    "        df.loc[val_idx, 'fold'] = fold\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae7e1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(927, 7) (2318, 2)\n",
      "raw data:\n",
      "train patients 189 train slides 251\n",
      "\n",
      "eliminate wrong Bboxes:\n",
      "train patients 185 train slides 247\n",
      "train no label in presence_of_lesion: {'j2SwPa04fq', 'cXmgCgA2fB'}\n",
      "fold: 0\n",
      "train patients 170 , train slides: 230\n",
      "test patients 103 , test slides: 121\n",
      "train patches: 69779 test patches: 39643\n",
      "\n",
      "\n",
      "fold: 1\n",
      "train patients 178 , train slides: 235\n",
      "test patients 97 , test slides: 111\n",
      "train patches: 72300 test patches: 36389\n",
      "\n",
      "\n",
      "fold: 2\n",
      "train patients 168 , train slides: 225\n",
      "test patients 99 , test slides: 113\n",
      "train patches: 66908 test patches: 35667\n",
      "\n",
      "\n",
      "fold: 3\n",
      "train patients 179 , train slides: 234\n",
      "test patients 91 , test slides: 106\n",
      "train patches: 70413 test patches: 35270\n",
      "\n",
      "\n",
      "fold: 4\n",
      "train patients 172 , train slides: 226\n",
      "test patients 96 , test slides: 120\n",
      "train patches: 69624 test patches: 42513\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_patches = pd.read_csv('../data/processed/dataframe_training_selected.csv')\n",
    "test_patches = pd.read_csv('../data/processed/dataframe_testing_selected.csv')\n",
    "final_df = pd.concat([train_patches, test_patches], ignore_index=True).sample(frac=1)\n",
    "\n",
    "df_train = pd.read_csv('../data/raw/train.csv')\n",
    "df_lesions = pd.read_csv('../data/raw/presence_of_lesion.csv')\n",
    "print(df_train.shape, df_lesions.shape)\n",
    "\n",
    "df_train['patient'] = df_train['filename'].apply(lambda x: x.split('_')[0])\n",
    "df_train['width']=df_train['x2']-df_train['x1']\n",
    "df_train['height']=df_train['y2']-df_train['y1']\n",
    "\n",
    "df_lesions['patient'] = df_lesions['file_name'].apply(lambda x: x.split('.')[0])\n",
    "all_patients = len(df_train[\"patient\"].unique())\n",
    "df_wrong = pd.read_csv('../data/raw/wrong_bbox.csv')\n",
    "print('raw data:')\n",
    "print(\"train patients\", len(df_train['patient'].unique()), \"train slides\",len(df_train['filename'].unique()),)\n",
    "\n",
    "indices = []\n",
    "for p in df_wrong.filename.unique():\n",
    "    for x1,x2, y1, y2 in df_wrong.loc[df_wrong[\"filename\"]==p][[\"x1\", \"x2\", \"y1\", \"y2\"]].values:\n",
    "        indices.append(df_train.loc[(df_train[\"filename\"]==p) & (df_train[\"x1\"]==int(x1))].index.item())\n",
    "df_train = df_train.drop(indices)\n",
    "\n",
    "print(\"\\neliminate wrong Bboxes:\")\n",
    "print(\"train patients\", len(df_train['patient'].unique()), \"train slides\",len(df_train['filename'].unique()),)\n",
    "print(\"train no label in presence_of_lesion:\",set(df_train['patient'].unique())-set(df_lesions['patient'].unique()))\n",
    "\n",
    "train_cols = ['patient','filename', 'x1', 'x2', 'y1', 'y2', 'max_x', 'max_y', \"width\", \"height\", 'presence_of_lesion']\n",
    "df_train = pd.merge(df_train, df_lesions, on=[\"patient\"])[train_cols]\n",
    "\n",
    "\n",
    "df_with_folds = create_stratified_folds(df_train, n_splits=n_splits, target_column='presence_of_lesion')\n",
    "Path(\"../data/processed/crossval_sets\").mkdir(parents=True, exist_ok=True)\n",
    "for fold in range(n_splits):\n",
    "    print('fold:', fold)\n",
    "    df_train_cv = df_with_folds[df_with_folds['fold'] != fold]\n",
    "    df_test_cv = df_with_folds[df_with_folds['fold'] == fold]\n",
    "    train_slides = df_train_cv['filename'].unique().tolist()\n",
    "    test_slides = df_test_cv['filename'].unique().tolist()\n",
    "\n",
    "    print(\"train patients\", len(df_train_cv['patient'].unique()),', train slides:', len(train_slides))\n",
    "    print(\"test patients\", len(df_test_cv['patient'].unique()),', test slides:', len(test_slides))\n",
    "    train_patches = final_df.loc[final_df['filename'].isin(df_train_cv['filename'])]\n",
    "    test_patches = final_df.loc[final_df['filename'].isin(df_test_cv['filename'])]\n",
    "    print('train patches:', len(train_patches), 'test patches:', len(test_patches))\n",
    "    train_patches.to_csv('../data/processed/crossval_sets/dataframe_training_Fold' + str(fold) + '.csv', index=False)\n",
    "    test_patches.to_csv('../data/processed/crossval_sets/dataframe_testing_Fold' + str(fold) + '.csv', index=False)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37733cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa5b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
